<!DOCTYPE html>
<html>
<body> 
<h1># Spatial-Language-Tutorial</h1>
<h1>Representation, Learning and Reasoning on Spatial Language for Downstream NLP Tasks</h1>
<h2>Speakers:</h2>
<h3>Parisa Kordjamshidi</h3>
<p>Michigan State University</p>
<p>kordjams@msu.edu</p>
<h3>James Pustejovsky</h3>
<p>Brandeis University</p>
<p>jamesp@cs.brandeis.edu</p>
<h3>Marie-Francine Moens</h3>
<p>KU Leuven</p>
<p>sien.moens@cs.kuleuven.be</p>
<h2>Abstract</h2>
<p>Understating spatial semantics expressed in natural language can become highly complex in real-world applications. This includes applications of language grounding, navigation, visual question answering, and more generic human-machine interaction and dialogue systems. In many of such downstream tasks, explicit representation of spatial concepts and relationships can improve the capabilities of machine learning models in reasoning and deep language understanding. In this tutorial, we overview the cutting-edge research results and existing challenges related to spatial language understanding including semantic annotations,  existing corpora, symbolic and sub-symbolic representations, qualitative spatial reasoning, spatial common sense, deep and structured learning models.  We discuss the recent results on the above-mentioned applications --that need spatial language learning and reasoning -- and highlight the research gaps and future directions.</p>
<p><a href="https://heler.slack.com/files/UCFDZ0UHZ/F01EDV5TCDU/33_paper.pdf"></a>33_Paper</p>
</body>
</html>  
